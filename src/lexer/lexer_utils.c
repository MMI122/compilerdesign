/*
 * NatureLang Compiler
 * Copyright (c) 2026
 * 
 * Lexer Utility Functions Implementation
 * 
 * Additional lexer support functions not generated by Flex.
 */

#include "lexer.h"
#include "tokens.h"
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

/* ============================================================================
 * TOKEN LIST IMPLEMENTATION
 * ============================================================================
 */

TokenList *token_list_create(void) {
    TokenList *list = (TokenList *)malloc(sizeof(TokenList));
    if (list == NULL) {
        fprintf(stderr, "Error: Failed to allocate token list\n");
        return NULL;
    }
    list->head = NULL;
    list->tail = NULL;
    list->count = 0;
    return list;
}

void token_list_append(TokenList *list, Token *token) {
    if (list == NULL || token == NULL) return;
    
    TokenNode *node = (TokenNode *)malloc(sizeof(TokenNode));
    if (node == NULL) {
        fprintf(stderr, "Error: Failed to allocate token node\n");
        return;
    }
    
    node->token = token;
    node->next = NULL;
    
    if (list->tail == NULL) {
        list->head = node;
        list->tail = node;
    } else {
        list->tail->next = node;
        list->tail = node;
    }
    list->count++;
}

void token_list_free(TokenList *list) {
    if (list == NULL) return;
    
    TokenNode *current = list->head;
    while (current != NULL) {
        TokenNode *next = current->next;
        token_free(current->token);
        free(current);
        current = next;
    }
    
    free(list);
}

TokenList *lexer_tokenize_all(void) {
    TokenList *list = token_list_create();
    if (list == NULL) return NULL;
    
    Token *token;
    do {
        token = lexer_next_token();
        if (token == NULL) {
            fprintf(stderr, "Error: lexer_next_token returned NULL\n");
            break;
        }
        token_list_append(list, token);
    } while (token->type != TOK_EOF && token->type != TOK_ERROR);
    
    return list;
}

void token_list_print(const TokenList *list) {
    if (list == NULL) {
        printf("(null token list)\n");
        return;
    }
    
    printf("=== Token List (%d tokens) ===\n", list->count);
    printf("%-5s %-20s %-15s %s\n", "NUM", "TYPE", "LEXEME", "LOCATION");
    printf("%-5s %-20s %-15s %s\n", "---", "----", "------", "--------");
    
    int num = 1;
    TokenNode *current = list->head;
    while (current != NULL) {
        Token *t = current->token;
        printf("%-5d %-20s %-15s %d:%d\n",
               num++,
               token_type_to_string(t->type),
               t->lexeme ? t->lexeme : "(null)",
               t->loc.first_line,
               t->loc.first_column);
        current = current->next;
    }
    printf("=== End Token List ===\n");
}

/* ============================================================================
 * ERROR RECOVERY FUNCTIONS
 * ============================================================================
 */

void lexer_skip_to_sync(void) {
    Token *token;
    do {
        token = lexer_next_token();
        if (token == NULL) break;
        
        TokenType type = token->type;
        token_free(token);
        
        /* Synchronization points: end of statement markers */
        if (type == TOK_EOF ||
            type == TOK_END ||
            type == TOK_NEWLINE ||
            type == TOK_SEMICOLON) {
            break;
        }
    } while (1);
}

void lexer_skip_to_eol(void) {
    Token *token;
    do {
        token = lexer_next_token();
        if (token == NULL) break;
        
        TokenType type = token->type;
        token_free(token);
        
        if (type == TOK_EOF || type == TOK_NEWLINE) {
            break;
        }
    } while (1);
}

/* ============================================================================
 * ADDITIONAL UTILITY FUNCTIONS
 * ============================================================================
 */

/**
 * Check if a string is a valid identifier (not a keyword)
 */
int lexer_is_valid_identifier(const char *str) {
    if (str == NULL || str[0] == '\0') return 0;
    
    /* First character must be letter or underscore */
    if (!((str[0] >= 'a' && str[0] <= 'z') ||
          (str[0] >= 'A' && str[0] <= 'Z') ||
          str[0] == '_')) {
        return 0;
    }
    
    /* Rest must be alphanumeric or underscore */
    for (int i = 1; str[i] != '\0'; i++) {
        char c = str[i];
        if (!((c >= 'a' && c <= 'z') ||
              (c >= 'A' && c <= 'Z') ||
              (c >= '0' && c <= '9') ||
              c == '_')) {
            return 0;
        }
    }
    
    /* Check it's not a keyword */
    return lookup_keyword(str) == TOK_IDENTIFIER;
}

/**
 * Get a descriptive name for a token suitable for error messages
 */
const char *lexer_describe_token(Token *token) {
    if (token == NULL) return "unknown token";
    
    static char buffer[256];
    
    switch (token->type) {
        case TOK_EOF:
            return "end of file";
        case TOK_ERROR:
            return "error";
        case TOK_INTEGER:
            snprintf(buffer, sizeof(buffer), "integer '%s'", token->lexeme);
            return buffer;
        case TOK_FLOAT:
            snprintf(buffer, sizeof(buffer), "decimal '%s'", token->lexeme);
            return buffer;
        case TOK_STRING:
            snprintf(buffer, sizeof(buffer), "text \"%s\"", 
                     token->value.string_value ? token->value.string_value : "");
            return buffer;
        case TOK_IDENTIFIER:
            snprintf(buffer, sizeof(buffer), "name '%s'", 
                     token->value.string_value ? token->value.string_value : token->lexeme);
            return buffer;
        default:
            if (token_is_keyword(token->type)) {
                snprintf(buffer, sizeof(buffer), "keyword '%s'", token->lexeme);
                return buffer;
            } else if (token_is_operator(token->type)) {
                snprintf(buffer, sizeof(buffer), "operator '%s'", token->lexeme);
                return buffer;
            } else {
                snprintf(buffer, sizeof(buffer), "'%s'", token->lexeme ? token->lexeme : "?");
                return buffer;
            }
    }
}
